<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bipo.pipelines.model_specific_preprocessing.nodes &mdash; BIPO Demand Forecasting v1.0.0 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/assets/bipo_docs.css" type="text/css" />
      <link rel="stylesheet" href="/opt/anaconda3/envs/bipo-df/lib/python3.8/site-packages/kedro/framework/html/_static/css/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="/opt/anaconda3/envs/bipo-df/lib/python3.8/site-packages/kedro/framework/html/_static/css/qb1-sphinx-rtd.css" type="text/css" />
      <link rel="stylesheet" href="/opt/anaconda3/envs/bipo-df/lib/python3.8/site-packages/kedro/framework/html/_static/css/theme-overrides.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js?v=0ec76b63"></script>
        <script src="../../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../../_static/copybutton.js?v=f281be69"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            BIPO Demand Forecasting
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../overview.html">BIPO Demand Forecasting Module: Project Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../overview.html#purpose-of-documentation">Purpose of Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../overview.html#architecture">Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#software-components">Software Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#deployment-architecture">Deployment Architecture</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../overview.html#deployment-package-contents">Deployment Package Contents</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#configuration">Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#data">Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#docker-images">Docker images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#logs">Logs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#trained-model-file-s">Trained model file(s)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#notebooks">Notebooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#scripts">Scripts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#os-port-usage">OS port usage</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Setup</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../inference-deployment-env-setup.html">Deployment Environment Setup - Inference Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#pre-requisites">Pre-requisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#system-specifications">System Specifications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#installation-of-binaries-and-dependencies-in-os">Installation of binaries and dependencies in OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#installing-from-script">Installing from script</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#list-of-installed-binaries-and-versions">List of installed binaries and versions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#python-dependencies">Python Dependencies</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#preliminary-steps">Preliminary Steps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#getting-started">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#checking-docker-service">Checking Docker Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#starting-and-stopping-docker-containers">Starting and Stopping Docker Containers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#lifting-of-firewall-ports-in-vm-if-needed">Lifting of firewall ports in VM (if needed)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../training-deployment-env-setup.html">Deployment Environment Setup - Training Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#pre-requisites">Pre-requisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-deployment-env-setup.html#system-specifications">System Specifications</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#installation-of-dependencies-in-windows">Installation of dependencies in Windows</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-deployment-env-setup.html#python-dependencies">Python Dependencies</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#getting-started">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#running-training-pipeline-in-docker-container">Running Training Pipeline in Docker Container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#setting-up-mlflow-on-the-local-machine-optional">Setting up MLflow on the Local Machine (Optional)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../kedro-overview.html">Overview of Kedro (v0.18.11)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../kedro-overview.html#what-is-kedro">What is Kedro?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../kedro-overview.html#elements-of-kedro">Elements of Kedro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../kedro-overview.html#creating-kedro-pipelines">Creating Kedro Pipelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../kedro-overview.html#pipeline-registry">Pipeline Registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../kedro-overview.html#registry-list">Registry List</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../kedro-overview.html#running-specific-pipelines">Running Specific Pipelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data-pipeline.html">Data Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-sources">Data Sources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#design-architecture">Design Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-loading-validation">1. Data Loading &amp; Validation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#input">Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#output">Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-preprocessing">2. Data Preprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id1">Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id2">Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-merging-splitting">3. Data Merging &amp; Splitting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id3">Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id4">Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#feature-engineering">4. Feature Engineering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#feature-inventory">Feature Inventory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#model-specific-preprocessing">5. Model-specific Preprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id5">Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id6">Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-pipeline-configuration">Data Pipeline Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#key-parameters-in-the-parameters-yml-file">Key Parameters in the <code class="docutils literal notranslate"><span class="pre">parameters.yml</span></code> File</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#key-parameters-in-the-constants-yml-file">Key Parameters in the <code class="docutils literal notranslate"><span class="pre">constants.yml</span></code> File</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#key-parameters-in-the-data-split-yml-file">Key Parameters in the <code class="docutils literal notranslate"><span class="pre">data_split.yml</span></code> File</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#how-to-execute-the-data-pipeline">How to Execute the Data Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#logging">Logging</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../training-pipeline.html">Training Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#pipeline-design">Pipeline Design</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#design-considerations">Design Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#flowchart">Flowchart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#choice-of-models">Choice of Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#training-pipeline-configuration">Training Pipeline Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#key-parameters-in-the-parameters-yml-file">Key Parameters in the <code class="docutils literal notranslate"><span class="pre">parameters.yml</span></code> File</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#model-hyperparameters-in-the-model-training-yml-file">Model Hyperparameters in the <code class="docutils literal notranslate"><span class="pre">model_training.yml</span></code> File</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#orderedmodel">OrderedModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#explainable-boosting-machine-ebm">Explainable Boosting Machine (EBM)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#model-input-data-definition">Model Input Data Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#how-to-run">How to Run</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#batch-script-docker-container">1. Batch Script (Docker Container)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#what-run-model-training-bat-does">What <code class="docutils literal notranslate"><span class="pre">run_model_training.bat</span></code> does</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#executing-the-script">Executing the script</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#kedro-command">2. Kedro Command</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#id1">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#id2">Executing the script</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#model-evaluation">Model Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#file-structure-in-container">File Structure in Container</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Serving</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../inference-endpoint.html">Model Serving Endpoint</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#how-to-run-endpoint">How to Run Endpoint</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#starting-the-endpoint">1. Starting the Endpoint</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#interacting-with-the-api-through-swagger-ui">2. Interacting with the API through Swagger UI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#terminating-the-endpoint">3. Terminating the Endpoint</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#request-format">Request Format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#optional-fields">Optional Fields</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#response-format">Response Format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#mapping-of-sales-class-id-to-sales-class-name">Mapping of <code class="docutils literal notranslate"><span class="pre">sales_class_id</span></code> to <code class="docutils literal notranslate"><span class="pre">sales_class_name</span></code>:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../inference-endpoint.html#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#api-error-codes">API Error Codes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../inference-module.html">Inference Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-module.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-module.html#flowchart">Flowchart</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-module.html#pipeline-configuration">Pipeline Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-module.html#file-structure-in-container">File Structure in Container</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Supplementary Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules.html">bipo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../bipo.html">bipo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../bipo.html#subpackages">Subpackages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../bipo.pipelines.html">bipo.pipelines package</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">BIPO Demand Forecasting</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">bipo.pipelines.model_specific_preprocessing.nodes</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for bipo.pipelines.model_specific_preprocessing.nodes</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This is a boilerplate pipeline &#39;model_specific_preprocessing&#39;</span>
<span class="sd">generated using Kedro 0.18.11</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">OrderedDict</span> <span class="k">as</span> <span class="n">OrdDict</span>
<span class="kn">from</span> <span class="nn">kedro.config</span> <span class="kn">import</span> <span class="n">ConfigLoader</span>
<span class="kn">from</span> <span class="nn">kedro.io</span> <span class="kn">import</span> <span class="n">DataSetError</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OrdinalEncoder</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">from</span> <span class="nn">bipo</span> <span class="kn">import</span> <span class="n">settings</span>

<span class="c1"># This will get the active logger during run time</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">settings</span><span class="o">.</span><span class="n">LOGGER_NAME</span><span class="p">)</span>
<span class="n">conf_loader</span> <span class="o">=</span> <span class="n">ConfigLoader</span><span class="p">(</span><span class="n">conf_source</span><span class="o">=</span><span class="n">settings</span><span class="o">.</span><span class="n">CONF_SOURCE</span><span class="p">)</span>
<span class="n">const_dict</span> <span class="o">=</span> <span class="n">conf_loader</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;constants*&quot;</span><span class="p">)</span>

<span class="c1"># DEFAULT CONSTANTS</span>
<span class="n">DEFAULT_DATE_COL</span> <span class="o">=</span> <span class="n">const_dict</span><span class="p">[</span><span class="s2">&quot;default_date_col&quot;</span><span class="p">]</span>


<div class="viewcode-block" id="remove_unnecessary_columns_and_rows"><a class="viewcode-back" href="../../../../bipo.pipelines.model_specific_preprocessing.html#bipo.pipelines.model_specific_preprocessing.nodes.remove_unnecessary_columns_and_rows">[docs]</a><span class="k">def</span> <span class="nf">remove_unnecessary_columns_and_rows</span><span class="p">(</span>
    <span class="n">partitioned_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span> <span class="n">params_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which drops features identified by parameters names with prefix fe in parameters.yml which is accessed through params_dict.</span>

<span class="sd">    Args:</span>
<span class="sd">        partitioned_data (Dict[str, pd.DataFrame]): Kedro MemoryDataSet dictionary containing individual outlet related features dataframe as values with filename using outlet as identifier.</span>
<span class="sd">        params_dict (Dict): Dictionary referencing parameters.yml.</span>


<span class="sd">    Raises:</span>
<span class="sd">        None</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, pd.DataFrame]: Dictionary containing processed dataframe identified by its input identifier.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Identify parameters with &#39;fe&#39; prefixes and outlet_column_name key</span>
    <span class="n">fe_prefix_params</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">params</span>
        <span class="k">for</span> <span class="n">params</span> <span class="ow">in</span> <span class="n">params_dict</span>
        <span class="k">if</span> <span class="n">params</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;fe&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">params</span> <span class="o">==</span> <span class="s2">&quot;outlet_column_name&quot;</span>
    <span class="p">]</span>

    <span class="n">columns_to_drop</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Read off parameters with fe prefixes</span>
    <span class="k">for</span> <span class="n">fe_params</span> <span class="ow">in</span> <span class="n">fe_prefix_params</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reading </span><span class="si">{</span><span class="n">fe_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">parameters_input</span> <span class="o">=</span> <span class="n">params_dict</span><span class="p">[</span><span class="n">fe_params</span><span class="p">]</span>

        <span class="c1"># Flatten multi dimension list into single list</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters_input</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="c1"># List of list</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">parameters_input</span><span class="p">):</span>
                <span class="n">parameters_input</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">parameters_input</span><span class="p">))</span>
            <span class="c1"># Simple list</span>
            <span class="n">columns_to_drop</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">parameters_input</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters_input</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">columns_to_drop</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">parameters_input</span><span class="p">)</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">parameters_input</span><span class="p">,</span> <span class="n">Dict</span><span class="p">):</span>
            <span class="n">columns_to_drop</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">parameters_input</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The parameters </span><span class="si">{</span><span class="n">fe_params</span><span class="si">}</span><span class="s2"> processed is neither a str or list or Dict type, continuing to next parameter.&quot;</span>
            <span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;The overall list of columns to drop are as follows: </span><span class="si">{</span><span class="n">columns_to_drop</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">columns_to_drop</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">partition_id</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">partitioned_data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">validated_col_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
                <span class="nb">set</span><span class="p">(</span><span class="n">columns_to_drop</span><span class="p">)</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
            <span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Shape of data for </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2"> before dropping </span><span class="si">{</span><span class="n">validated_col_list</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

            <span class="c1"># Drop unwanted columns which are validated</span>
            <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">validated_col_list</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="c1"># Drop rows with nulls</span>
            <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of data for </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2"> is </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">partitioned_data</span><span class="p">[</span><span class="n">partition_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span>

    <span class="k">return</span> <span class="n">partitioned_data</span></div>


<div class="viewcode-block" id="concat_same_folds_of_outlet_data"><a class="viewcode-back" href="../../../../bipo.pipelines.model_specific_preprocessing.html#bipo.pipelines.model_specific_preprocessing.nodes.concat_same_folds_of_outlet_data">[docs]</a><span class="k">def</span> <span class="nf">concat_same_folds_of_outlet_data</span><span class="p">(</span>
    <span class="n">partitioned_input</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function that loads and concatenates vertically all outlet data belonging to the same fold together.</span>

<span class="sd">    Args:</span>
<span class="sd">        partitioned_input (Dict[str, pd.DataFrame]): Kedro IncrementalDataSet dictionary containing individual outlet related features dataframe as values with filename using outlet as identifier.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, pd.DataFrame]: Dictionary containing concatenated fold-based outlet data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Dummy variable to track fold number being processed so as to ensure concatenation is applied to folds with same number.</span>
    <span class="n">current_fold</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">merged_fold_outlet_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">partition_id</span><span class="p">,</span> <span class="n">partition_df</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">partitioned_input</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># Extract fold_information from the partition_id. Create new empty dataframe when new fold is processed with a new shortened partition id. This shortened partition converts fold partition files e.g &#39;testing_fold1_expanding_window_param_90&#39; to &#39;testing_fold1_expanding_window_param&#39;.</span>
        <span class="n">new_fold</span> <span class="o">=</span> <span class="n">partition_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">new_fold</span> <span class="o">!=</span> <span class="n">current_fold</span><span class="p">:</span>
            <span class="n">merged_outlet_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing fold: </span><span class="si">{</span><span class="n">new_fold</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># Construct new identifier with outlet id removed.</span>
            <span class="n">new_partition_id</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">partition_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>

        <span class="c1"># Merge loaded</span>

        <span class="n">partition_data</span> <span class="o">=</span> <span class="n">partition_df</span>
        <span class="n">merged_outlet_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">merged_outlet_df</span><span class="p">,</span> <span class="n">partition_data</span><span class="p">],</span> <span class="n">join</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Concatenated </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2"> to existing dataframe.&quot;</span><span class="p">)</span>
        <span class="n">current_fold</span> <span class="o">=</span> <span class="n">new_fold</span>
        <span class="n">merged_fold_outlet_dict</span><span class="p">[</span><span class="n">new_partition_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">merged_outlet_df</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Concatenated all outlets of each fold.&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">merged_fold_outlet_dict</span></div>


<div class="viewcode-block" id="reorder_data"><a class="viewcode-back" href="../../../../bipo.pipelines.model_specific_preprocessing.html#bipo.pipelines.model_specific_preprocessing.nodes.reorder_data">[docs]</a><span class="k">def</span> <span class="nf">reorder_data</span><span class="p">(</span>
    <span class="n">partitioned_input_training</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="n">partitioned_input_validation</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">OrdDict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which pairs file from training and validation subfolders by using an OrderedDict to update corresponding alternating training, validation prefix folds before model training can be done.</span>

<span class="sd">    Args:</span>
<span class="sd">        partitioned_input_training (Dict[str, pd.DataFrame]): Kedro MemoryDataset Dictionary containing training folds of data.</span>
<span class="sd">        partitioned_input_validation (Dict[str, pd.DataFrame): Kedro MemoryDataset Dictionary containing validation folds of data</span>

<span class="sd">    Returns:</span>
<span class="sd">        typing.OrderedDict[str, pd.DataFrame]): Dictionary containing paired ordering of training and validation outlets datasets.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">ordered_dict</span> <span class="o">=</span> <span class="n">OrderedDict</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">training_outlet_folds</span><span class="p">,</span> <span class="n">validation_outlet_folds</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="nb">sorted</span><span class="p">(</span><span class="n">partitioned_input_training</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
        <span class="nb">sorted</span><span class="p">(</span><span class="n">partitioned_input_validation</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Pairing </span><span class="si">{</span><span class="n">training_outlet_folds</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">validation_outlet_folds</span><span class="si">}</span><span class="s2"> in order&quot;</span>
        <span class="p">)</span>
        <span class="c1"># Pair training and validation in such order as they are related by name. Only difference is the use of different prefixes, training and validation for their purpose.</span>
        <span class="n">ordered_dict</span><span class="p">[</span><span class="n">training_outlet_folds</span><span class="p">]</span> <span class="o">=</span> <span class="n">partitioned_input_training</span><span class="p">[</span>
            <span class="n">training_outlet_folds</span>
        <span class="p">]</span>
        <span class="n">ordered_dict</span><span class="p">[</span><span class="n">validation_outlet_folds</span><span class="p">]</span> <span class="o">=</span> <span class="n">partitioned_input_validation</span><span class="p">[</span>
            <span class="n">validation_outlet_folds</span>
        <span class="p">]</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Reordered files in the following order: </span><span class="si">{</span><span class="n">ordered_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">ordered_dict</span></div>


<div class="viewcode-block" id="identify_const_column"><a class="viewcode-back" href="../../../../bipo.pipelines.model_specific_preprocessing.html#bipo.pipelines.model_specific_preprocessing.nodes.identify_const_column">[docs]</a><span class="k">def</span> <span class="nf">identify_const_column</span><span class="p">(</span>
    <span class="n">partitioned_input</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="n">params_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which applies necessary model specific preprocessing steps based on the model parameters defined in params_dict and subsequently splits data into X (feature), y (target) components.</span>

<span class="sd">    Args:</span>
<span class="sd">        partitioned_input (Dict[str, pd.DataFrame]): Non-PartitionedDataset</span>
<span class="sd">        dictionary containing file, and dataframe.</span>
<span class="sd">        params_dict (Dict): Dictionary referencing parameters.yml.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict: Dictionary containing processed folds, containing column information which are constants.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Instantiate an empty dictionary for storing constant column feature name</span>
    <span class="n">const_column_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="c1"># Generates X,y datasets for each partition data based on mode set</span>
    <span class="k">for</span> <span class="p">(</span>
        <span class="n">partition_id</span><span class="p">,</span>
        <span class="n">partition_df</span><span class="p">,</span>
    <span class="p">)</span> <span class="ow">in</span> <span class="n">partitioned_input</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading data from </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load data from each partitioned file</span>
        <span class="n">fold</span> <span class="o">=</span> <span class="n">partition_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Handle model specific preprocessing:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dropping rows with nulls for </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">partition_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s2">&quot;any&quot;</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">const_column_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">partition_df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">partition_df</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Constant columns: </span><span class="si">{</span><span class="n">const_column_list</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Update dictionary</span>
        <span class="n">const_column_dict</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span> <span class="o">=</span> <span class="n">const_column_list</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Completed model specific data preprocessing.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">const_column_dict</span></div>


<div class="viewcode-block" id="remove_const_column"><a class="viewcode-back" href="../../../../bipo.pipelines.model_specific_preprocessing.html#bipo.pipelines.model_specific_preprocessing.nodes.remove_const_column">[docs]</a><span class="k">def</span> <span class="nf">remove_const_column</span><span class="p">(</span>
    <span class="n">partitioned_input</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="n">params_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="n">const_column_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which applies necessary model specific preprocessing steps based on the model parameters defined in params_dict and subsequently splits data into X (feature), y (target) components.</span>

<span class="sd">    Args:</span>
<span class="sd">        partitioned_input (Dict[str, pd.DataFrame]): Non-PartitionedDataset dictionary containing file, and dataframe.</span>
<span class="sd">        params_dict (Dict): Dictionary referencing parameters.yml.</span>
<span class="sd">        const_column_dict (Dict[str, List]): Dictionary containing fold-based columns which are constant (only 1 unique value)</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict: Dictionary containing processed dataframe folds.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Instantiate an empty dictionary for storing X,y splits</span>
    <span class="n">data_partition_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="c1"># Generates X,y datasets for each partition data based on mode set</span>
    <span class="k">for</span> <span class="p">(</span>
        <span class="n">partition_id</span><span class="p">,</span>
        <span class="n">partition_df</span><span class="p">,</span>
    <span class="p">)</span> <span class="ow">in</span> <span class="n">partitioned_input</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading data from </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load data from each partitioned file</span>
        <span class="n">fold</span> <span class="o">=</span> <span class="n">partition_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Before dropping any null: </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2"> with shape </span><span class="si">{</span><span class="n">partition_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="c1"># Drop rows containing any nulls as entry as they are invalid.</span>
        <span class="n">const_column_list</span> <span class="o">=</span> <span class="n">const_column_dict</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Retrieved fold-based constant column information&quot;</span><span class="p">)</span>

        <span class="c1"># Drop learned constant columns based on training data in current dataset to ensure consistency.</span>
        <span class="k">if</span> <span class="n">const_column_list</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Dropping </span><span class="si">{</span><span class="n">const_column_list</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">partition_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">const_column_list</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No columns required to drop for this fold: </span><span class="si">{</span><span class="n">fold</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processed </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2"> with shape </span><span class="si">{</span><span class="n">partition_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># Update dict with processed dataframe</span>
        <span class="n">data_partition_dict</span><span class="p">[</span><span class="n">partition_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">partition_df</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Completed model specific data preprocessing.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">data_partition_dict</span></div>


<div class="viewcode-block" id="split_data_into_X_y_features"><a class="viewcode-back" href="../../../../bipo.pipelines.model_specific_preprocessing.html#bipo.pipelines.model_specific_preprocessing.nodes.split_data_into_X_y_features">[docs]</a><span class="k">def</span> <span class="nf">split_data_into_X_y_features</span><span class="p">(</span>
    <span class="n">dataframe_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">],</span> <span class="n">params_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which splits a provided dataframe residing in each entry of dataframe_dict by a given target_column parameters into feature and target components.</span>

<span class="sd">    Depending on the prefix of the input dataframe_dict keys, the dataframes are then categorised into training/validation/testing categories. It assumes the target_column passed in is valid.</span>

<span class="sd">    Args:</span>
<span class="sd">        partitioned_input (Dict[str, str]): Dictionary containing file,         lazy-loading function key-value mapping based on Kedro framework.</span>
<span class="sd">        params_dict (Dict[str, Any]): Dictionary referenced from parameters.yml</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[Dict[str, pd.DataFrame],Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]]: Tuple of dictionary representing training, validation and testing datasets</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">target_column</span> <span class="o">=</span> <span class="n">params_dict</span><span class="p">[</span><span class="s2">&quot;target_column_for_modeling&quot;</span><span class="p">]</span>
    <span class="n">train_data_partition_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">val_data_partition_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">test_data_partition_dict</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">df_id</span><span class="p">,</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">dataframe_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">target_column</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The specified target column for modeling </span><span class="si">{</span><span class="n">target_columns</span><span class="si">}</span><span class="s2"> is not found. Returning empty dictionary.</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">data_partition_dict</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Separating features and target columns. Object based features will be dropped. Also columns with null will be dropped to avoid model training issues.&quot;</span>
        <span class="p">)</span>

        <span class="n">y_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="n">target_column</span><span class="p">]]</span>
        <span class="n">X_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">target_column</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;object&quot;</span><span class="p">])</span>

        <span class="c1"># Drop columns with null. This could be caused by unseen encoding which may not appear in training data but instead validation data due to time period differences. </span>
        <span class="n">nan_cols_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">X_df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">X_df</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">any</span><span class="p">()]</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Identified columns with nulls </span><span class="si">{</span><span class="n">nan_cols_list</span><span class="si">}</span><span class="s2"> after selecting non-object datatype.&quot;</span><span class="p">)</span>
        <span class="n">X_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">nan_cols_list</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Convert filename structure training_fold1_expanding_window_param_0_X</span>
        <span class="c1"># to training_fold1_expanding_window</span>
        <span class="n">filename_substring</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">df_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
        <span class="c1"># Update dict with splits</span>
        <span class="k">if</span> <span class="n">df_id</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;train&quot;</span><span class="p">):</span>
            <span class="n">train_data_partition_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename_substring</span><span class="si">}</span><span class="s2">_X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_df</span>
            <span class="n">train_data_partition_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename_substring</span><span class="si">}</span><span class="s2">_y&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_df</span>
        <span class="k">elif</span> <span class="n">df_id</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;validation&quot;</span><span class="p">):</span>
            <span class="n">val_data_partition_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename_substring</span><span class="si">}</span><span class="s2">_X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_df</span>
            <span class="n">val_data_partition_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename_substring</span><span class="si">}</span><span class="s2">_y&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_df</span>
        <span class="k">elif</span> <span class="n">df_id</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;testing&quot;</span><span class="p">):</span>
            <span class="n">test_data_partition_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename_substring</span><span class="si">}</span><span class="s2">_X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_df</span>
            <span class="n">test_data_partition_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">filename_substring</span><span class="si">}</span><span class="s2">_y&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_df</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Created features of shape </span><span class="si">{</span><span class="n">X_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and target </span><span class="si">{</span><span class="n">y_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> for </span><span class="si">{</span><span class="n">df_id</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Completed feature/target splits for each fold.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">train_data_partition_dict</span><span class="p">,</span> <span class="n">val_data_partition_dict</span><span class="p">,</span> <span class="n">test_data_partition_dict</span></div>


<div class="viewcode-block" id="merge_tsfresh_features_with_outlets"><a class="viewcode-back" href="../../../../bipo.pipelines.model_specific_preprocessing.html#bipo.pipelines.model_specific_preprocessing.nodes.merge_tsfresh_features_with_outlets">[docs]</a><span class="k">def</span> <span class="nf">merge_tsfresh_features_with_outlets</span><span class="p">(</span>
    <span class="n">partitioned_outlet_input</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="n">partitioned_tsfresh_input</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which left merges a outlet-based generated tsfresh features to each outlet based on common time-index. As the id used for both partitioned inputs are the same, joining can be simply made by using one of the id retreived from either of the inputs and doing a direct referencing from both dictionary keys.</span>

<span class="sd">    Args:</span>
<span class="sd">        partitioned_outlet_input: Dict[str, pd.DataFrame]: Dataframe partitioned by outlets loaded in Kedro MemoryDataSet on the fly without any physical file presence or Kedro PartitionedDataSet as a source.</span>
<span class="sd">        partitioned_mmm_input: Dict[str, pd.DataFrame]: PartitionedDataset of fold-based tsfresh features dataframe.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]: Dictionary containing merged dataframes involving both tsfresh features and input outlet dataframe features. Otherwise, returns partitioned_outlet_input with dataframe lazy loading function.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">partitioned_tsfresh_input</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;No tsfresh features to merge, skipping merging of such features to outlet dataframes.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">partitioned_outlet_input</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Merging tsfresh features with fold outlets...&quot;</span><span class="p">)</span>
    <span class="n">merged_partitioned_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">partitioned_id</span><span class="p">,</span> <span class="n">partitioned_df</span> <span class="ow">in</span> <span class="n">partitioned_outlet_input</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">outlet_fold_df</span> <span class="o">=</span> <span class="n">partitioned_df</span>

        <span class="n">outlet_fold_df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">outlet_fold_df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load the corresponding fold in lightweightmmm partitions</span>
        <span class="n">tsfresh_fold_df</span> <span class="o">=</span> <span class="n">partitioned_tsfresh_input</span><span class="p">[</span><span class="n">partitioned_id</span><span class="p">]()</span>
        <span class="n">tsfresh_fold_df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">tsfresh_fold_df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">outlet_fold_tsfresh_df</span> <span class="o">=</span> <span class="n">outlet_fold_df</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
            <span class="n">tsfresh_fold_df</span><span class="p">,</span>
            <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Drop excess columns with _y suffix due to emrge</span>
        <span class="n">col_with_y_suffix</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">outlet_fold_tsfresh_df</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_y&quot;</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">outlet_fold_tsfresh_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_with_y_suffix</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">merged_partitioned_dict</span><span class="p">[</span><span class="n">partitioned_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlet_fold_tsfresh_df</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Completed Tsfresh features merged with folds.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">merged_partitioned_dict</span></div>


<div class="viewcode-block" id="merge_mmm_features_with_fold_outlets"><a class="viewcode-back" href="../../../../bipo.pipelines.model_specific_preprocessing.html#bipo.pipelines.model_specific_preprocessing.nodes.merge_mmm_features_with_fold_outlets">[docs]</a><span class="k">def</span> <span class="nf">merge_mmm_features_with_fold_outlets</span><span class="p">(</span>
    <span class="n">partitioned_outlet_input</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="n">partitioned_mmm_input</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which left merges a fold-based generated LightweightMMM features to each outlet based on common time-index. This is on the assumption that LightweightMMM features are applicable across all-outlets regardless of outlet types.</span>

<span class="sd">    Args:</span>
<span class="sd">        partitioned_outlet_input (Dict[str, pd.DataFrame]): Dataframe partitioned by outlets from Kedro PartitionedDataSet.</span>
<span class="sd">        partitioned_mmm_input (Dict[str, pd.DataFrame]): Generated fold-based LightweightMMM features dataframe partitioned by folds.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, pd.DataFrame]: Dictionary containing merged dataframes involving both lightweightMMM features and input outlet dataframe features. Otherwise, returns partitioned_outlet_input with dataframe lazy loading function.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">partitioned_mmm_input</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;No lightweightMMM features to merge, skipping merging of such features to outlet dataframes.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">partitioned_outlet_input</span>
    <span class="n">merged_partitioned_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="c1"># Catch cases when partitioned_mmm_input is empty</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Merging lightweightmmm features with fold outlets...&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">partitioned_id</span><span class="p">,</span> <span class="n">partitioned_df</span> <span class="ow">in</span> <span class="n">partitioned_outlet_input</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Retrieve fold information from partitioned_outlet_input</span>
        <span class="n">fold_info</span> <span class="o">=</span> <span class="n">partitioned_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">outlet_fold_df</span> <span class="o">=</span> <span class="n">partitioned_df</span>

        <span class="n">outlet_fold_df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">outlet_fold_df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Load the corresponding fold in lightweightmmm partitions</span>
        <span class="n">mmm_fold_df</span> <span class="o">=</span> <span class="n">partitioned_mmm_input</span><span class="p">[</span><span class="n">fold_info</span><span class="p">]</span>
        <span class="n">mmm_fold_df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">mmm_fold_df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">outlet_fold_mmm_df</span> <span class="o">=</span> <span class="n">outlet_fold_df</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
            <span class="n">mmm_fold_df</span><span class="p">,</span>
            <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Drop excess columns with _y suffix due to emrge</span>
        <span class="n">col_with_y_suffix</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">outlet_fold_mmm_df</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_y&quot;</span><span class="p">)]</span>
        <span class="n">outlet_fold_mmm_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">col_with_y_suffix</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">merged_partitioned_dict</span><span class="p">[</span><span class="n">partitioned_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlet_fold_mmm_df</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Completed LightweightMMM features merged with folds.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">merged_partitioned_dict</span></div>


<div class="viewcode-block" id="merge_fold_and_generated_lag"><a class="viewcode-back" href="../../../../bipo.pipelines.model_specific_preprocessing.html#bipo.pipelines.model_specific_preprocessing.nodes.merge_fold_and_generated_lag">[docs]</a><span class="k">def</span> <span class="nf">merge_fold_and_generated_lag</span><span class="p">(</span>
    <span class="n">fold_based_outlet_partitioned_data</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
    <span class="n">generated_lags_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which merges a dictionary containing calculated outlet lagged values into a dictionary containing fold based outlet partitioned dataframe.</span>

<span class="sd">    Args:</span>
<span class="sd">        fold_based_outlet_partitioned_data (Dict[str, pd.DataFrame): Dictionary containing fold based outlet partitioned dataframes which are distinguished by fold and outlet information in the dictionary key.</span>
<span class="sd">        generated_lags_dict (Dict[str, pd.DataFrame): PartitionedDataset dictionary containing outlet-based lagged features stored as Kedro PartitionedDataSet that is accessible via its lazy loading function.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, pd.DataFrame]: Dictionary containing updated dataframe with lagged features if applicable. Else return same as input.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Loop through the dictionary and join the outlet dataframe with lag values with the fold-based outlet dataframes to create an updated dataframe with lagged features.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">generated_lags_dict</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;No lag features to merge, skipping merging of such features to outlet dataframes.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">fold_based_outlet_partitioned_data</span>

    <span class="k">for</span> <span class="p">(</span>
        <span class="n">fold_based_outlet_id</span><span class="p">,</span>
        <span class="n">fold_based_outlet_df</span><span class="p">,</span>
    <span class="p">)</span> <span class="ow">in</span> <span class="n">fold_based_outlet_partitioned_data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Fold based id is of the form eg. training_fold1_expanding_window_param_90_305</span>
        <span class="n">outlet_info</span> <span class="o">=</span> <span class="n">fold_based_outlet_id</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">fold_based_outlet_df</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">fold_based_outlet_df</span> <span class="o">=</span> <span class="n">fold_based_outlet_df</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fold_based_outlet_df</span> <span class="o">=</span> <span class="n">fold_based_outlet_df</span><span class="p">()</span>

        <span class="n">fold_based_outlet_df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span>
            <span class="n">fold_based_outlet_df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Assume lag features dataframe filename are prefix with lag_</span>
        <span class="n">generated_lag_df</span> <span class="o">=</span> <span class="n">generated_lags_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;lag_</span><span class="si">{</span><span class="n">outlet_info</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>

        <span class="n">generated_lag_df</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span>
            <span class="n">generated_lag_df</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">fold_based_outlet_df</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
            <span class="n">generated_lag_df</span><span class="p">,</span>
            <span class="n">how</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
            <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">suffixes</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="s2">&quot;_y&quot;</span><span class="p">),</span>
        <span class="p">)</span>

        <span class="c1"># Drop excess column with suffixes _y as defined during merge</span>
        <span class="n">columns_with_y_suffixes</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;_)y&quot;</span><span class="p">)]</span>
        <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">columns_with_y_suffixes</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Update lag col list at first instance. This is consistent across folds and outlets since the difference only lies in the time index, with all features the same.</span>
        <span class="n">lag_col_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;lag_&quot;</span><span class="p">)]</span>

        <span class="c1"># Drop rows which are impacted by nans</span>
        <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="n">lag_col_list</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Successfully merged </span><span class="si">{</span><span class="n">fold_based_outlet_id</span><span class="si">}</span><span class="s2"> with shape: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">fold_based_outlet_partitioned_data</span><span class="p">[</span><span class="n">fold_based_outlet_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="s2">&quot;Finished merging of lag features with main data folds. Returning generated lag features.</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">fold_based_outlet_partitioned_data</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, AI Singapore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>