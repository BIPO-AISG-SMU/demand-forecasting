<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>bipo.pipelines.data_loader.nodes &mdash; BIPO Demand Forecasting v1.0.0 documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/assets/bipo_docs.css" type="text/css" />
      <link rel="stylesheet" href="/opt/anaconda3/envs/bipo-df/lib/python3.8/site-packages/kedro/framework/html/_static/css/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="/opt/anaconda3/envs/bipo-df/lib/python3.8/site-packages/kedro/framework/html/_static/css/qb1-sphinx-rtd.css" type="text/css" />
      <link rel="stylesheet" href="/opt/anaconda3/envs/bipo-df/lib/python3.8/site-packages/kedro/framework/html/_static/css/theme-overrides.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js?v=0ec76b63"></script>
        <script src="../../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../../_static/sphinx_highlight.js?v=4825356b"></script>
        <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
        <script src="../../../../_static/copybutton.js?v=f281be69"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            BIPO Demand Forecasting
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../overview.html">BIPO Demand Forecasting Module: Project Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../overview.html#purpose-of-documentation">Purpose of Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../overview.html#architecture">Architecture</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#software-components">Software Components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#deployment-architecture">Deployment Architecture</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../overview.html#deployment-package-contents">Deployment Package Contents</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#configuration">Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#data">Data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#docker-images">Docker images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#logs">Logs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#trained-model-file-s">Trained model file(s)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#notebooks">Notebooks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#scripts">Scripts</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../overview.html#os-port-usage">OS port usage</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Setup</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../inference-deployment-env-setup.html">Deployment Environment Setup - Inference Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#pre-requisites">Pre-requisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#system-specifications">System Specifications</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#installation-of-binaries-and-dependencies-in-os">Installation of binaries and dependencies in OS</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#installing-from-script">Installing from script</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#list-of-installed-binaries-and-versions">List of installed binaries and versions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#python-dependencies">Python Dependencies</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#preliminary-steps">Preliminary Steps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#getting-started">Getting Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#checking-docker-service">Checking Docker Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#starting-and-stopping-docker-containers">Starting and Stopping Docker Containers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-deployment-env-setup.html#lifting-of-firewall-ports-in-vm-if-needed">Lifting of firewall ports in VM (if needed)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../training-deployment-env-setup.html">Deployment Environment Setup - Training Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#pre-requisites">Pre-requisites</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-deployment-env-setup.html#system-specifications">System Specifications</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#installation-of-dependencies-in-windows">Installation of dependencies in Windows</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-deployment-env-setup.html#python-dependencies">Python Dependencies</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#getting-started">Getting Started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#running-training-pipeline-in-docker-container">Running Training Pipeline in Docker Container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-deployment-env-setup.html#setting-up-mlflow-on-the-local-machine-optional">Setting up MLflow on the Local Machine (Optional)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Data Pipeline</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../kedro-overview.html">Overview of Kedro (v0.18.11)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../kedro-overview.html#what-is-kedro">What is Kedro?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../kedro-overview.html#elements-of-kedro">Elements of Kedro</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../kedro-overview.html#creating-kedro-pipelines">Creating Kedro Pipelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../kedro-overview.html#pipeline-registry">Pipeline Registry</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../kedro-overview.html#registry-list">Registry List</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../kedro-overview.html#running-specific-pipelines">Running Specific Pipelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data-pipeline.html">Data Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-sources">Data Sources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#design-architecture">Design Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-loading-validation">1. Data Loading &amp; Validation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#input">Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#output">Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-preprocessing">2. Data Preprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id1">Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id2">Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-merging-splitting">3. Data Merging &amp; Splitting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id3">Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id4">Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#feature-engineering">4. Feature Engineering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#feature-inventory">Feature Inventory</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#model-specific-preprocessing">5. Model-specific Preprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id5">Input</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#id6">Output</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#data-pipeline-configuration">Data Pipeline Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#key-parameters-in-the-parameters-yml-file">Key Parameters in the <code class="docutils literal notranslate"><span class="pre">parameters.yml</span></code> File</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#key-parameters-in-the-constants-yml-file">Key Parameters in the <code class="docutils literal notranslate"><span class="pre">constants.yml</span></code> File</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#key-parameters-in-the-data-split-yml-file">Key Parameters in the <code class="docutils literal notranslate"><span class="pre">data_split.yml</span></code> File</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../data-pipeline.html#how-to-execute-the-data-pipeline">How to Execute the Data Pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../data-pipeline.html#logging">Logging</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../training-pipeline.html">Training Pipeline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#pipeline-design">Pipeline Design</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#design-considerations">Design Considerations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#flowchart">Flowchart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#choice-of-models">Choice of Models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#training-pipeline-configuration">Training Pipeline Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#key-parameters-in-the-parameters-yml-file">Key Parameters in the <code class="docutils literal notranslate"><span class="pre">parameters.yml</span></code> File</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#model-hyperparameters-in-the-model-training-yml-file">Model Hyperparameters in the <code class="docutils literal notranslate"><span class="pre">model_training.yml</span></code> File</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#orderedmodel">OrderedModel</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#explainable-boosting-machine-ebm">Explainable Boosting Machine (EBM)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#model-input-data-definition">Model Input Data Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#how-to-run">How to Run</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#batch-script-docker-container">1. Batch Script (Docker Container)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#what-run-model-training-bat-does">What <code class="docutils literal notranslate"><span class="pre">run_model_training.bat</span></code> does</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#executing-the-script">Executing the script</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../training-pipeline.html#kedro-command">2. Kedro Command</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#id1">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../training-pipeline.html#id2">Executing the script</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#model-evaluation">Model Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../training-pipeline.html#file-structure-in-container">File Structure in Container</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Serving</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../inference-endpoint.html">Model Serving Endpoint</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#how-to-run-endpoint">How to Run Endpoint</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#starting-the-endpoint">1. Starting the Endpoint</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#interacting-with-the-api-through-swagger-ui">2. Interacting with the API through Swagger UI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#terminating-the-endpoint">3. Terminating the Endpoint</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#request-format">Request Format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#optional-fields">Optional Fields</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#response-format">Response Format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-endpoint.html#mapping-of-sales-class-id-to-sales-class-name">Mapping of <code class="docutils literal notranslate"><span class="pre">sales_class_id</span></code> to <code class="docutils literal notranslate"><span class="pre">sales_class_name</span></code>:</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../inference-endpoint.html#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-endpoint.html#api-error-codes">API Error Codes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../inference-module.html">Inference Module</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-module.html#overview">Overview</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../inference-module.html#flowchart">Flowchart</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-module.html#pipeline-configuration">Pipeline Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../inference-module.html#file-structure-in-container">File Structure in Container</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Supplementary Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules.html">bipo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../bipo.html">bipo</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../bipo.html#subpackages">Subpackages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../bipo.pipelines.html">bipo.pipelines package</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">BIPO Demand Forecasting</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">bipo.pipelines.data_loader.nodes</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for bipo.pipelines.data_loader.nodes</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This is a boilerplate pipeline &#39;data_loader&#39;</span>
<span class="sd">generated using Kedro 0.18.10</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span> <span class="nn">kedro.io</span> <span class="kn">import</span> <span class="n">DataSetError</span><span class="p">,</span> <span class="n">DataCatalog</span>
<span class="kn">from</span> <span class="nn">kedro.config</span> <span class="kn">import</span> <span class="n">ConfigLoader</span>

<span class="kn">from</span> <span class="nn">bipo</span> <span class="kn">import</span> <span class="n">settings</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">dateutil</span> <span class="kn">import</span> <span class="n">parser</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">settings</span><span class="o">.</span><span class="n">LOGGER_NAME</span><span class="p">)</span>
<span class="n">conf_loader</span> <span class="o">=</span> <span class="n">ConfigLoader</span><span class="p">(</span><span class="n">conf_source</span><span class="o">=</span><span class="n">settings</span><span class="o">.</span><span class="n">CONF_SOURCE</span><span class="p">)</span>
<span class="n">const_dict</span> <span class="o">=</span> <span class="n">conf_loader</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;constants*&quot;</span><span class="p">)</span>
<span class="c1"># DEFAULT CONSTANTS</span>
<span class="n">DEFAULT_DATE_COL</span> <span class="o">=</span> <span class="n">const_dict</span><span class="p">[</span><span class="s2">&quot;default_date_col&quot;</span><span class="p">]</span>


<div class="viewcode-block" id="merge_unique_daily_partitions"><a class="viewcode-back" href="../../../../bipo.pipelines.data_loader.html#bipo.pipelines.data_loader.nodes.merge_unique_daily_partitions">[docs]</a><span class="k">def</span> <span class="nf">merge_unique_daily_partitions</span><span class="p">(</span>
    <span class="n">partitioned_input</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which merges all data partitions (dataframes) from unique_daily_records subfolder on a date column (as reference from the global variable) with an instantiated dataframe containing a column containing date values which covers the date period of interest.</span>

<span class="sd">    This is supported through the call of merge_unique_csv_xlsx_df function.</span>

<span class="sd">    Args:</span>
<span class="sd">        partitioned_input (Dict[str, pd.DataFrame]): Dictionary containing file name of csv/xlsx and the pointer to its loading function as per Kedro PartitionedDataset definiton.</span>

<span class="sd">    Raises:</span>
<span class="sd">        DataSetError: When no data is available for loading in Kedro PartitionDataSet.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame: Merged dataframe if no exception. Else None when DataSetError is encountered.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Create an new dataframe representing the date period of interest. This would be used for merging with other dataframes in data partitions</span>
    <span class="n">combine_df</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># Apply merge for each dataframe in the data partition input</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">partitioned_input</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">partition_id</span><span class="p">,</span> <span class="n">partition_df</span> <span class="ow">in</span> <span class="n">partitioned_input</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading data: </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># By default the dataframe loaded would not use any column as index.</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">partition_df</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded data is of shape </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># Apply standard renaming</span>
        <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
            <span class="n">columns</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">rename_columns</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">renamed_date_col</span> <span class="o">=</span> <span class="n">rename_columns</span><span class="p">(</span><span class="n">DEFAULT_DATE_COL</span><span class="p">)</span>
        <span class="c1"># Apply pd.to_datetime conversion</span>
        <span class="n">df</span><span class="p">[</span><span class="n">renamed_date_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">renamed_date_col</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">combine_df</span> <span class="o">==</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2"> as base..&quot;</span><span class="p">)</span>
            <span class="n">combine_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="k">continue</span>

        <span class="c1"># Do merge if there is more than 1 file in the partition, otherwise left as it is.</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Attempting to merge </span><span class="si">{</span><span class="n">partition_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Check if the date column appears in incoming dataframe and existing dataframe</span>
        <span class="k">if</span> <span class="n">renamed_date_col</span> <span class="ow">in</span> <span class="n">df</span><span class="p">:</span>
            <span class="n">combine_df</span> <span class="o">=</span> <span class="n">merge_unique_csv_xlsx_df</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">combine_df</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;After merging: dataframe is of shape </span><span class="si">{</span><span class="n">combine_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Skipping merge due to no common date columns&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Setting </span><span class="si">{</span><span class="n">renamed_date_col</span><span class="si">}</span><span class="s2"> as index&quot;</span><span class="p">)</span>
    <span class="n">combine_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">renamed_date_col</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">combine_df</span></div>



<div class="viewcode-block" id="merge_unique_csv_xlsx_df"><a class="viewcode-back" href="../../../../bipo.pipelines.data_loader.html#bipo.pipelines.data_loader.nodes.merge_unique_csv_xlsx_df">[docs]</a><span class="k">def</span> <span class="nf">merge_unique_csv_xlsx_df</span><span class="p">(</span>
    <span class="n">df_to_merge</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">base_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which merges two dataframe using right merge (df_to_merge to base_df) base on global DEFAULT_DATE_COL which represents the common date col of the dataframe. It assumes all dataframe columns are renamed to at least a lowercase.</span>

<span class="sd">    Args:</span>
<span class="sd">        df_to_merge (pd.DataFrame): DataFrame representing a specific dataset of interest</span>
<span class="sd">        base_df (pd.DataFrame): DataFrame representing a dataset containing mixture of datasets column which is to be merged onto.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame: Merged dataframe.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">renamed_date_col</span> <span class="o">=</span> <span class="n">rename_columns</span><span class="p">(</span><span class="n">DEFAULT_DATE_COL</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">combine_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span>
            <span class="n">df_to_merge</span><span class="p">,</span>
            <span class="n">base_df</span><span class="p">,</span>
            <span class="n">how</span><span class="o">=</span><span class="s2">&quot;outer&quot;</span><span class="p">,</span>
            <span class="n">left_on</span><span class="o">=</span><span class="n">renamed_date_col</span><span class="p">,</span>
            <span class="n">right_on</span><span class="o">=</span><span class="n">renamed_date_col</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to merge on index due to differences.&quot;</span><span class="p">)</span>
        <span class="n">combine_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_to_merge</span><span class="p">,</span> <span class="n">base_df</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s2">&quot;cross&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current merged dataframe </span><span class="si">{</span><span class="n">combine_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">combine_df</span></div>


<div class="viewcode-block" id="rename_merge_unique_csv_xlsx_df_col_index"><a class="viewcode-back" href="../../../../bipo.pipelines.data_loader.html#bipo.pipelines.data_loader.nodes.rename_merge_unique_csv_xlsx_df_col_index">[docs]</a><span class="k">def</span> <span class="nf">rename_merge_unique_csv_xlsx_df_col_index</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;This function renames all columns and set the renamed date related column as index.</span>

<span class="sd">    Args:</span>
<span class="sd">        df: Dataframe to be processed.</span>

<span class="sd">    Raises:</span>
<span class="sd">        None</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame: Merged dataframe.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Apply reset to ensure all column names are captured.</span>
    <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">rename_columns</span><span class="p">(</span><span class="n">col</span><span class="p">)</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>

    <span class="c1"># Select the column which is of datetime</span>
    <span class="n">datetime_col</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;datetime&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="c1"># Assume default date col is not renamed, we want to retain its original form</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">datetime_col</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Setting identified first instance datetime column as index and standardise its naming&quot;</span>
        <span class="p">)</span>
        <span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">datetime_col</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Rename date index to DEFAULT_DATE_COL instead as used commonly.</span>
        <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="n">DEFAULT_DATE_COL</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;No relevant date column found in dataframe.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">df</span></div>


<div class="viewcode-block" id="load_and_partition_proxy_revenue_data"><a class="viewcode-back" href="../../../../bipo.pipelines.data_loader.html#bipo.pipelines.data_loader.nodes.load_and_partition_proxy_revenue_data">[docs]</a><span class="k">def</span> <span class="nf">load_and_partition_proxy_revenue_data</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which partitions the proxy revenue data by its outlet column into smaller datasets.</span>

<span class="sd">    Args:</span>
<span class="sd">        df (pd.DataFrame): DataFrame containing daily outlet proxy revenue data.</span>

<span class="sd">    Raises:</span>
<span class="sd">        KeyError: When specified column to access is not found in dataframe.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict: Dictionary containing filename and partitioned dataframe.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">outlet_part_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Partitioning outlet revenue data&quot;</span><span class="p">)</span>

    <span class="c1"># Read column name</span>
    <span class="n">outlet_col</span> <span class="o">=</span> <span class="n">const_dict</span><span class="p">[</span><span class="s2">&quot;default_outlet_column&quot;</span><span class="p">]</span>
    <span class="n">unique_outlet_list</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">outlet_col</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">outlet</span> <span class="ow">in</span> <span class="n">unique_outlet_list</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processing outlet: </span><span class="si">{</span><span class="n">outlet</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">outlet_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">outlet_col</span><span class="p">]</span> <span class="o">==</span> <span class="n">outlet</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
            <span class="c1"># Set date as index and save dataframe as a partition (where index is saved)</span>
            <span class="n">outlet_df</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="n">DEFAULT_DATE_COL</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Renamed columns after partitioning: </span><span class="si">{</span><span class="n">outlet_df</span><span class="o">.</span><span class="n">columns</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Propensity data is of shape </span><span class="si">{</span><span class="n">outlet_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">outlet_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
                <span class="n">columns</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">rename_columns</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
                <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># .csv will be appended as defined in catalog.yml</span>
            <span class="n">outlet_part_dict</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;proxy_revenue_</span><span class="si">{</span><span class="n">outlet</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outlet_df</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Completed partitioning of all outlet revenue data.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">outlet_part_dict</span>

    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to access required column: </span><span class="si">{</span><span class="n">outlet_col</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="load_and_structure_propensity_data"><a class="viewcode-back" href="../../../../bipo.pipelines.data_loader.html#bipo.pipelines.data_loader.nodes.load_and_structure_propensity_data">[docs]</a><span class="k">def</span> <span class="nf">load_and_structure_propensity_data</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which load and restructre propensity data by deriving daily aggregated mean using region-based propensity to spend factor.</span>

<span class="sd">    Args:</span>
<span class="sd">        df (pd.DataFrame): DataFrame containing daily region-based propensity to spend data.</span>

<span class="sd">    Raises:</span>
<span class="sd">        KeyError: When specified column to access is not found in dataframe.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame: Dataframe containing the mean-aggregated propensity to spend factor using all regional factors provided.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Aggregating region based propensity data to region based form&quot;</span><span class="p">)</span>
    <span class="c1"># Get the name of the column representing propensity data</span>
    <span class="n">factor_col</span> <span class="o">=</span> <span class="n">const_dict</span><span class="p">[</span><span class="s2">&quot;default_propensity_factor_column&quot;</span><span class="p">]</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">df</span><span class="p">[</span><span class="n">factor_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">factor_col</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;coerce&quot;</span><span class="p">)</span>

        <span class="c1"># Take mean value of propensity data to represent as national level</span>
        <span class="n">groupby_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">DEFAULT_DATE_COL</span><span class="p">)[[</span><span class="n">factor_col</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Renamed propensity data columns after groupby: </span><span class="si">{</span><span class="n">groupby_df</span><span class="o">.</span><span class="n">columns</span><span class="si">}</span><span class="s2"> with shape </span><span class="si">{</span><span class="n">groupby_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Apply standard renaming</span>
        <span class="n">groupby_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
            <span class="n">columns</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">rename_columns</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">groupby_df</span>

    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unable to access required column: </span><span class="si">{</span><span class="n">factor_col</span><span class="si">}</span><span class="s2">.</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="load_and_structure_marketing_data"><a class="viewcode-back" href="../../../../bipo.pipelines.data_loader.html#bipo.pipelines.data_loader.nodes.load_and_structure_marketing_data">[docs]</a><span class="k">def</span> <span class="nf">load_and_structure_marketing_data</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which load and restructre marketing data by converting it into a new dataset comprising daily-based marketing expenditure costs over respective marketing modes with names of active marketing campaign names</span>

<span class="sd">    Args:</span>
<span class="sd">        df (pd.DataFrame): Dataframe containing summarised marketing channel spends by campaigns.</span>

<span class="sd">    Raises:</span>
<span class="sd">        KeyError: When specified column to access is not found in dataframe.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame: Restructured dataframe containing daily-based marketing expenditure costs over respective marketing modes with names of active marketing campaign names.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Apply pivoting for marketing data using campaign info, with total cost serving as values for various mode</span>

    <span class="n">mkt_channel_col_name</span> <span class="o">=</span> <span class="n">const_dict</span><span class="p">[</span><span class="s2">&quot;default_mkt_channels_column&quot;</span><span class="p">]</span>
    <span class="n">mkt_cost_col_name</span> <span class="o">=</span> <span class="n">const_dict</span><span class="p">[</span><span class="s2">&quot;default_mkt_cost_column&quot;</span><span class="p">]</span>
    <span class="n">mkt_name_col</span> <span class="o">=</span> <span class="n">const_dict</span><span class="p">[</span><span class="s2">&quot;default_mkt_name_column&quot;</span><span class="p">]</span>
    <span class="n">date_start</span><span class="p">,</span> <span class="n">date_end</span> <span class="o">=</span> <span class="n">const_dict</span><span class="p">[</span><span class="s2">&quot;default_mkt_date_start_end_columns&quot;</span><span class="p">]</span>
    <span class="n">mkt_channel_col_list</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">mkt_channel_col_name</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">df_pivot</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span>
            <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="n">mkt_name_col</span><span class="p">,</span> <span class="n">date_start</span><span class="p">,</span> <span class="n">date_end</span><span class="p">],</span>
            <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">mkt_channel_col_name</span><span class="p">],</span>
            <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="n">mkt_cost_col_name</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="c1"># Drop campaigns where channel costs(mode) are all empty and fill nulls for remaining campaigns with some missing cost. Subsequently remove excess column level due to effects of pivoting</span>
        <span class="n">df_pivot</span> <span class="o">=</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">df_pivot</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">droplevel</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Convert marketing data to daily equivalent form. Note that some dates have duplicates due to different campaigns</span>
        <span class="n">df_pivot</span> <span class="o">=</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">rename_axis</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">df_pivot</span><span class="p">[</span><span class="n">DEFAULT_DATE_COL</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="n">date_start</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="n">x</span><span class="p">[</span><span class="n">date_end</span><span class="p">]),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
        <span class="p">)</span>
        <span class="n">df_pivot</span> <span class="o">=</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">explode</span><span class="p">(</span><span class="n">DEFAULT_DATE_COL</span><span class="p">)</span>

        <span class="c1"># Calculate duration between start and end and + 1 to include start date. subsequently adjust to daily average</span>

        <span class="n">df_pivot</span><span class="p">[</span><span class="s2">&quot;Duration&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_pivot</span><span class="p">[</span><span class="n">date_end</span><span class="p">]</span> <span class="o">-</span> <span class="n">df_pivot</span><span class="p">[</span><span class="n">date_start</span><span class="p">])</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">days</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">df_pivot</span><span class="p">[</span><span class="n">mkt_channel_col_list</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_pivot</span><span class="p">[</span><span class="n">mkt_channel_col_list</span><span class="p">]</span><span class="o">.</span><span class="n">div</span><span class="p">(</span>
            <span class="n">df_pivot</span><span class="p">[</span><span class="s2">&quot;Duration&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>

        <span class="c1"># Generate a mkt list and date info df</span>
        <span class="n">mkt_date_df</span> <span class="o">=</span> <span class="n">df_pivot</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">DEFAULT_DATE_COL</span><span class="p">)[</span><span class="n">mkt_name_col</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>

        <span class="c1"># Daily mkt channel cost for each day</span>
        <span class="n">mkt_daily_cost_df</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">df_pivot</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">mkt_name_col</span><span class="p">)</span>
            <span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">DEFAULT_DATE_COL</span><span class="p">)[</span><span class="n">mkt_channel_col_list</span><span class="p">]</span>
            <span class="o">.</span><span class="n">sum</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># Merge the two created dataframe</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">mkt_date_df</span><span class="p">,</span> <span class="n">mkt_daily_cost_df</span><span class="p">,</span> <span class="n">left_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">right_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Rename only cost related information with daily_cost suffix, to ensure naming consistency across and their meaning after value transformation</span>
        <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
            <span class="n">columns</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">rename_columns</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;_daily_cost&quot;</span>
            <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">mkt_name_col</span>
            <span class="k">else</span> <span class="n">rename_columns</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
            <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Renamed marketing columns: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="si">}</span><span class="s2"> with shape </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">.&quot;</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">df</span>

    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unable to access required columns involving either of the columns: </span><span class="si">{</span><span class="n">mkt_name_col</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">date_start</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">date_end</span><span class="si">}</span><span class="s2"> ,</span><span class="si">{</span><span class="n">mkt_channel_col_name</span><span class="si">}</span><span class="s2">,</span><span class="si">{</span><span class="n">mkt_cost_col_name</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="load_and_structure_weather_data"><a class="viewcode-back" href="../../../../bipo.pipelines.data_loader.html#bipo.pipelines.data_loader.nodes.load_and_structure_weather_data">[docs]</a><span class="k">def</span> <span class="nf">load_and_structure_weather_data</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which applies mean aggregation of the region-based weather data involving temperature, rainfall and wind speeds. Other non-numerical features are dropped.</span>

<span class="sd">    Args:</span>
<span class="sd">        df (pd.DataFrame): DataFrame containing region-based weather related data</span>

<span class="sd">    Raises:</span>
<span class="sd">        KeyError: When specified column to access is not found in dataframe.</span>

<span class="sd">    Returns:</span>
<span class="sd">        pd.DataFrame: Dataframe containing the mean aggregated weather data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Consturct date using defined columns from constants.yml</span>
    <span class="n">date_col_list</span> <span class="o">=</span> <span class="n">const_dict</span><span class="p">[</span><span class="s2">&quot;columns_to_construct_date&quot;</span><span class="p">][</span><span class="s2">&quot;weather_data&quot;</span><span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Constructing date from </span><span class="si">{</span><span class="n">date_col_list</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="n">date_col_list</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">date_col_list</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="n">DEFAULT_DATE_COL</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span>
            <span class="n">df</span><span class="p">[</span><span class="n">date_col_list</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Removing </span><span class="si">{</span><span class="n">date_col_list</span><span class="si">}</span><span class="s2"> as </span><span class="si">{</span><span class="n">DEFAULT_DATE_COL</span><span class="si">}</span><span class="s2"> has been constructed.</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="n">date_col_list</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Attempt to access dataframe features based on </span><span class="si">{</span><span class="n">date_col_list</span><span class="si">}</span><span class="s2"> but at least one is not in.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Aggregate region using mean</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Applying mean aggregation for all columns&quot;</span><span class="p">)</span>

    <span class="c1"># Filter out date related columns to facilitate groupby because of possible nans occurring for numerical columns.</span>
    <span class="n">non_date_col</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">col</span> <span class="o">!=</span> <span class="n">DEFAULT_DATE_COL</span> <span class="ow">and</span> <span class="n">col</span> <span class="o">!=</span> <span class="n">date_col_list</span>
    <span class="p">]</span>

    <span class="c1"># Coerce possible numeric features to numeric, else as it is</span>
    <span class="n">df</span><span class="p">[</span><span class="n">non_date_col</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">non_date_col</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">,</span> <span class="n">errors</span><span class="o">=</span><span class="s2">&quot;coerce&quot;</span><span class="p">)</span>

    <span class="c1"># Only numerical columns would be mean aggregated, others would be nans due to object type, which would be dropped since we are only interested in numeric columns</span>
    <span class="n">groupby_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">DEFAULT_DATE_COL</span><span class="p">,</span> <span class="n">dropna</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="n">non_date_col</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="n">groupby_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span>
        <span class="n">columns</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">rename_columns</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
        <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">groupby_df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Renamed weather data columns after groupby: </span><span class="si">{</span><span class="n">groupby_df</span><span class="o">.</span><span class="n">columns</span><span class="si">}</span><span class="s2"> with shape </span><span class="si">{</span><span class="n">groupby_df</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="se">\n</span><span class="s2">.&quot;</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">groupby_df</span></div>


<div class="viewcode-block" id="rename_columns"><a class="viewcode-back" href="../../../../bipo.pipelines.data_loader.html#bipo.pipelines.data_loader.nodes.rename_columns">[docs]</a><span class="k">def</span> <span class="nf">rename_columns</span><span class="p">(</span><span class="n">string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Function which rename a string by lowercasing, stripping trailing and leading spaces, replacing spaces inbetween words with _ and finally remove non-alphanumeric characters (except _).</span>

<span class="sd">    Example: &#39; Date #$Q(&#39; becomes &#39;date_q&#39;</span>

<span class="sd">    Args:</span>
<span class="sd">        string (str): Input string</span>

<span class="sd">    Raises:</span>
<span class="sd">        None</span>

<span class="sd">    Returns:</span>
<span class="sd">        str: Processed string if input is not None. Else default &#39;unknown&#39; string is returned instead.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">string</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">new_string</span> <span class="o">=</span> <span class="n">string</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;_&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;[^a-zA-Z0-9_]&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">new_string</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Encountered other type, not processing&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">string</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, AI Singapore.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>