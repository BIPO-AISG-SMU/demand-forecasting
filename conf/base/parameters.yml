# This is a boilerplate parameters config generated for pipeline using Kedro 0.18.10.
#
# Documentation for this file format can be found in "Parameters"
# Link: https://docs.kedro.org/en/0.18.10/kedro_project_setup/configuration.html#parameters

####### Datapreprocess configurations.
# Start and end date should be in YYYY-MM-DD format. Example: 2021-01-01
start_date: "2021-01-01"
end_date: "2022-12-31"

# Caters to % instances of zero valued causing binning issue. Between 0 and 100.
# Other values would be overriden by constants.yml
zero_val_threshold_perc: 2
# List of costcentre/outlets to exclude from pipeline
outlets_exclusion_list: []

# ----------------------------------------------------------------------
####### Feature Engineering configurations.
# The following are the columns of the dataframe post split.

# Date, costcentrecode, manhours, proxyrevenue, location, outlet, type,daily_rainfall_total_mm, highest_30_min_rainfall_mm, highest_60_min_rainfall_mm,highest_120_min_rainfall_mm, mean_temperature_c, maximum_temperature_c,minimum_temperature_c, mean_wind_speed_kmh, max_wind_speed_kmh, factor,group_size_cap, school_holiday, school_holiday_type, public_holiday,public_holiday_type, day, name, tv_ad,radio_ad, instagram_ad,facebook_ad,youtube_ad, poster_campaign, digital

###### Time agnostic feature engineering section
# List of columns to be after feature engineering (not including tsfresh)
fe_columns_to_drop_list: [
    "day",
    "location",
    "manhours",
    "outlet",
    "highest_30_min_rainfall_mm",
    "highest_60_min_rainfall_mm",
    "highest_120_min_rainfall_mm",
    "min_temperature_c",
    "mean_temperature_c",
    "mean_wind_speed_kmh",
    "max_wind_speed_kmh",
    "school_holiday_type",
    "public_holiday_type",
]

# Column representing marketing event column
fe_mkt_column_name: "name"

# Dictionary containing values for imputation related to marketing features excluding marketing campaign.
mkt_columns_to_impute_dict: {
    "tv_ad_daily_cost": 0,
    "radio_ad_daily_cost": 0,
    "instagram_ad_daily_cost": 0,
    "facebook_ad_daily_cost": 0,
    "youtube_ad_daily_cost": 0,
    "poster_campaign_daily_cost": 0,
    "digital_daily_cost": 0,
}

# -----------------------------------------------------------------------
###### Time-agnostic features categorsiation. 

# NOTE: Parameters prefixed with 'fe' are columns which would be dropped after relevant encoding/transformation. They are depended by the code for conducting such activity.

#Possible options: simple_split, expanding_window or sliding_window.
split_approach_source: "expanding_window"

# 
outlet_column_name: "costcentrecode"
#
##########################
# Column specific features for feature engineer involving conversion to boolean state based on hard coded condition. This would not need to be changed so long as there is no change in the names of columns concerned
##########################

# Daily rainfall related column for use in creating 'is_raining' boolean feature.
# Officially defined as having “rained” if the total rainfall for that day is 0.2mm or more.
fe_rainfall_column: "daily_rainfall_total_mm"

# Holiday related columns to use for generating its equivalent boolean state: # "school_holiday", "public_holiday". A corresponding prefix 'is' will be appended to the specified list of column.
fe_holiday_column_list: ["school_holiday", "public_holiday"]

# Pandemic related column for generating its equivalent boolean state:
fe_pandemic_column: "group_size_cap"

# Columns to be applied differencing. List of list with inner list containing only 2 elements. Example [["minimum_temperature_c","maximum_temperature_c"]]
columns_to_diff_list: [[]]

## Adstock 
include_adstock: False
adstock_value_threshold: 0.05 
adstock_days_threshold: 60
# marketing channel lag_weights 
tv_ad_lag_weight: 0.5
radio_ad_lag_weight: 0.5
instagram_ad_lag_weight: 0.5
facebook_ad_lag_weight: 0.5
youtube_ad_lag_weight: 0.5
poster_campaign_ad_lag_weight: 0.5
digital_lag_weight: 0.5

mkt_channel_list: ['tv_ad_daily_cost', 'radio_ad_daily_cost', 'instagram_ad_daily_cost', 'facebook_ad_daily_cost', 'youtube_ad_daily_cost','poster_campaign_daily_cost', 'digital_daily_cost']
# ----------------------------------------------------------------------
############### Time-dependent feature engineering

### NOTE: Parameters prefixed with 'fe' are columns which would be dropped after relevant encoding/transformation. They are depended by the code for conducting such activity. 

####### Target feature (the feature of interest).
fe_target_feature_name: "proxyrevenue"
## Dictionary containing columns to encode as well as the encoded labels
fe_ordinal_encoding_dict: {} #{"type" : ["carry-out","dine-in"]}

# Columns to encode: Please ensure they column to encode is not included in the columns_to_drop_list, as this would result in error. 
fe_one_hot_encoding_col_list: ["type"]

## Binning dictionary
binning_dict: { 
    "proxyrevenue": ["Low", "Medium", "High", "Exceptional"],
}


## Normalisation subsection
# Define columns to normalise based on above specified column information. Exclude lag features
columns_to_std_norm_list: []

# Whether to include lag columns for standardisation/normalisation.
# Set to False if all lag feature is not required for normalisation
include_lags_columns_for_std_norm: True

# Config for using either standardisation/normalisation. Only "normalize", "standardize" supported.
normalization_approach: "normalize"

# ----------------------------------------------------------------------
############################## Additional feature engineering
### NOTE: Parameters prefixed with 'fe' are columns which would be dropped after relevant encoding/transformation. They are depended by the code for conducting such activity. 

## Lag feature(s) generation section

## General lag features
# Column used for lag feature generation
columns_to_create_lag_features: ["proxyrevenue"]

# List of lag periods to generate prior to split. Values should be positive integers
lag_periods_list: [9, 14]

## Simple moving average lag generation
# List of window sizes simple moving average
sma_window_periods_list: [7]

# Week level equivalent of lag periods list to apply for weekly lags.
lag_week_periods_list: [1,2]

# ----------------------------------------------------------------------
###### Tsfresh related features section

# Config that determines whether pipeline should include tsfresh. Either True/False.
include_tsfresh: False

# Number of derived *tsfresh* features to use based on a derived list of tsfresh's combined_relevance_tables containing list of tsfresh features for each outlet that satisfies the `tsfresh_n_significant`, based on mean aggregated p-values sorted in ascending order.
tsfresh_num_features: 20 # Numerical

# Timeshift for *tsfresh* rolling time series' min/max timeshift parameter. Related to `tsfresh_features_list`.
tsfresh_days_per_group: 7

# Target feature which tsfresh feature generation relies on
tsfresh_target_feature: "binned_proxyrevenue"

# Feature which tsfresh rolling time series is applied, creating subwindows.
tsfresh_features_list: ["proxyrevenue"]

# Threshold determining which features should be statistically significant predictors for categorical target feature to be regarded as relevant
tsfresh_n_significant: 4

# Shared *Tsfresh* and *simple moving average* shift periods for the purpose of alignment in shift period. Based on the difference in number of days from the last date of predictions to be made and available data.
sma_tsfresh_shift_period: 9

# ----------------------------------------------------------------------
########## Used for model specific preprocessing, also used for training module

# Used for specifying predicted feature when performing X,y split
target_column_for_modeling: "binned_proxyrevenue"

# ----------------------------------------------------------------------
########## Used for model training/evaluation

## Model related and data fold related
# Model to use: "ordered_model" or "ebm"
model: "ebm"

# Data fold to pick for training/evaluation purposes
fold: 1

## MLflow Tracking Server
# Config that determines if mlflow is required.
enable_mlflow: True

# Config that determines if MLflow server used is remote
is_remote_mlflow: False

# URI of MLflow server
tracking_uri: "http://10.43.130.112:5005"

# MLflow experiment name to use, example experiment_name: bipo-ebm
experiment_name_prefix: "bipo"

## Model explainability. Only EBM supported

# Config that determines if explanability is required.
enable_explainability: True

# Output format to generate, either png or html
output_type: "html"

# any feature name of interest, or empty
feature_to_explain_list: ["factor", "is_weekday"]